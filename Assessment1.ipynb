{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "replacement_value = 'dummy_repalcement_value'\n",
    "path = '/home/td/Documents'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to set up the problem is to make it a binary classification task. This has the advantages of simplicity but it makes the assumption that large Makes share characteristics which is not always true. In this pass I solved the problem this way. \n",
    "\n",
    "A more thorough way to set up the problem would be to predict the make or a group of makes sharing similar characteristics and back into the probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TOYT    721411\n",
       "HOND    491961\n",
       "FORD    382695\n",
       "NISS    311324\n",
       "CHEV    297076\n",
       "BMW     199221\n",
       "MERZ    177307\n",
       "VOLK    149501\n",
       "HYUN    133864\n",
       "DODG    127764\n",
       "LEXS    124508\n",
       "KIA     101746\n",
       "JEEP    100909\n",
       "AUDI     84229\n",
       "MAZD     79853\n",
       "OTHR     72411\n",
       "GMC      62391\n",
       "CHRY     57317\n",
       "INFI     56809\n",
       "ACUR     52703\n",
       "SUBA     46898\n",
       "VOLV     42330\n",
       "TOYO     40064\n",
       "MITS     37842\n",
       "CADI     34080\n",
       "Name: Make, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label problems\n",
    "path = '/home/td/Documents'\n",
    "df = pd.read_csv('{path}/tickets.csv'.format(path=path), low_memory=False)\n",
    "\n",
    "top_25_makes = df['Make'].value_counts()[:25].index.tolist()\n",
    "df['Make'].value_counts()[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curation will be required, there is at least 1 duplicate with toyota and there are some invalid makes such as OTHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Latitude'] = df.loc[:,'Latitude'].replace(99999.0, np.nan)\n",
    "df.loc[:,'Longitude'] = df.loc[:,'Longitude'].replace(99999.0, np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ticket number</th>\n",
       "      <td>Ticket number</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Issue Date</th>\n",
       "      <td>Issue Date</td>\n",
       "      <td>0.006143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Issue time</th>\n",
       "      <td>Issue time</td>\n",
       "      <td>0.029601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meter Id</th>\n",
       "      <td>Meter Id</td>\n",
       "      <td>73.991538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marked Time</th>\n",
       "      <td>Marked Time</td>\n",
       "      <td>96.669739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP State Plate</th>\n",
       "      <td>RP State Plate</td>\n",
       "      <td>0.008767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plate Expiry Date</th>\n",
       "      <td>Plate Expiry Date</td>\n",
       "      <td>9.108706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIN</th>\n",
       "      <td>VIN</td>\n",
       "      <td>99.813099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Make</th>\n",
       "      <td>Make</td>\n",
       "      <td>50.062606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Body Style</th>\n",
       "      <td>Body Style</td>\n",
       "      <td>0.101879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color</th>\n",
       "      <td>Color</td>\n",
       "      <td>0.047158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>Location</td>\n",
       "      <td>0.009787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Route</th>\n",
       "      <td>Route</td>\n",
       "      <td>0.748956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agency</th>\n",
       "      <td>Agency</td>\n",
       "      <td>0.006246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violation code</th>\n",
       "      <td>Violation code</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violation Description</th>\n",
       "      <td>Violation Description</td>\n",
       "      <td>0.009993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fine amount</th>\n",
       "      <td>Fine amount</td>\n",
       "      <td>0.074570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>15.026185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>15.026185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 column_name  percent_missing\n",
       "Ticket number                  Ticket number         0.000000\n",
       "Issue Date                        Issue Date         0.006143\n",
       "Issue time                        Issue time         0.029601\n",
       "Meter Id                            Meter Id        73.991538\n",
       "Marked Time                      Marked Time        96.669739\n",
       "RP State Plate                RP State Plate         0.008767\n",
       "Plate Expiry Date          Plate Expiry Date         9.108706\n",
       "VIN                                      VIN        99.813099\n",
       "Make                                    Make        50.062606\n",
       "Body Style                        Body Style         0.101879\n",
       "Color                                  Color         0.047158\n",
       "Location                            Location         0.009787\n",
       "Route                                  Route         0.748956\n",
       "Agency                                Agency         0.006246\n",
       "Violation code                Violation code         0.000000\n",
       "Violation Description  Violation Description         0.009993\n",
       "Fine amount                      Fine amount         0.074570\n",
       "Latitude                            Latitude        15.026185\n",
       "Longitude                          Longitude        15.026185"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "percent_missing = df.isnull().sum()*100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are problems with the latitudes and longitudes, they don't make to standard coordinates. For example: Record with ticket id 1109139006 should have latitude and longitude of 34.156940, -118.435250. It has 6467477, 1880027 instead. Provided lat and long don't seem to map to standard formats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: check for differences in test and train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'feature_analysis.csv' does not exist: b'feature_analysis.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ba29dd54bad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_analysis.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'feature_analysis.csv' does not exist: b'feature_analysis.csv'"
     ]
    }
   ],
   "source": [
    "df_features = pd.read_csv('feature_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.sort_values('model_feature_importance', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('label_analysis.csv')\n",
    "df_labels = df_labels[df_labels['Make'].isin(top_25_makes)]\n",
    "df_counts= df_labels['Make'].value_counts()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "relevant_features = ['Fine amount', \n",
    "                     'plate_expiration_diff_ts', \n",
    "                     'lat_long_outlier_score', \n",
    "                     'route_dummy_replacement_value',\n",
    "                     'color_GY',\n",
    "                     'color_BL',\n",
    "                     'color_BK',\n",
    "                     'color_WT',\n",
    "                     'color_BL',\n",
    "                     'color_SL',\n",
    "                     'route_00600',\n",
    "                     'route_00500']\n",
    "\n",
    "\n",
    "for i in relevant_features:\n",
    "    scaler = StandardScaler()\n",
    "    df_labels.loc[:, i] =  scaler.fit_transform(df_labels[i].values.reshape(-1, 1))\n",
    "df_labels\n",
    "\n",
    "\n",
    "df_group = df_labels[['Make'] + relevant_features].groupby('Make').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "cluster_alg = KMeans(n_clusters = 2)\n",
    "df_group['cluster'] = cluster_alg.fit_predict(df_group[relevant_features])\n",
    "df_group.sort_values('cluster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group.groupby('cluster').mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 general type of features: location, car characteristics and ticket/violation characteristics. \n",
    "\n",
    "The best location features are the Route and ticket location density (lat_long_outlier_score). \n",
    "\n",
    "The best car characteristics features are the Body type and the car color. \n",
    "\n",
    "The best violation features are the fine amount and time of the violation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy = df_copy.dropna(subset = ['Make'])\n",
    "df_copy['target'] = df_copy['Make'].isin(top_25_makes).astype(int)\n",
    "df_copy.loc[:, 'ticket_dt'] = pd.to_datetime(df_copy['Issue Date'], errors='coerce')\n",
    "df_copy.loc[:, 'plate_expiration_diff_dt'] = pd.to_datetime(df_copy['Plate Expiry Date'].astype(int, errors = 'ignore'), format = '%Y%m', errors='coerce')\n",
    "df_copy.loc[:, 'plate_expiration_diff_dt'] = df_copy['plate_expiration_diff_dt'] - df['plate_expiration_diff_dt']\n",
    "df_copy.loc[:, 'plate_expiration_diff_ts'] = df_copy['plate_expiration_diff_dt'].values.astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_states = df_copy['RP State Plate'].value_counts()[:8].index.tolist()\n",
    "df_main_states = df_copy[df_copy['RP State Plate'].isin(top_states)]\n",
    "df_main_states.groupby(['RP State Plate'])['target'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_routes = df_copy['Route'].value_counts()[:8].index.tolist()\n",
    "df_route = df_copy[df_copy['Route'].isin(top_routes)]\n",
    "df_route.groupby(['Route'])['target'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_body_styles = df_copy['Body Style'].value_counts()[:8].index.tolist()\n",
    "df_body_styles = df_copy[df_copy['Body Style'].isin(top_body_styles)]\n",
    "df_body_styles.groupby(['Body Style'])['target'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_body_styles = df_copy['Issue time'].value_counts()[:8].index.tolist()\n",
    "df_body_styles = df_copy[df_copy['Issue time'].isin(top_body_styles)]\n",
    "df_body_styles.groupby(['Issue time'])['target'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.corr().sort_values('lat_long_outlier_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24072 269106 13273 129304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
