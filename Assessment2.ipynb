{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "path = '/home/td/Documents'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/td/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (0,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://s3-us-west-2.amazonaws.com/pcadsassessment/parking_citations.corrupted.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.to_csv('{path}/tickets.csv'.format(path = path), index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_most_common_makes(df):\n",
    "    return df['Make'].value_counts()[:25].index.tolist()\n",
    "\n",
    "\n",
    "def sqlite_most_common_names(conn):\n",
    "    res = conn.execute('''Select Make, COUNT(Make) As count_col\n",
    "                    from tickets\n",
    "                    group by Make\n",
    "                    order by count_col DESC\n",
    "                    LIMIT 25;''')\n",
    "    \n",
    "    res = [i[0] for i in res]\n",
    "    print('here', res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def pandas_most_common_color_per_make(df):\n",
    "    result_series =  df.groupby('Make')['Color'].agg(lambda x: x.value_counts(dropna = False).index[0])\n",
    "    return result_series.to_dict()\n",
    "\n",
    "\n",
    "def sqlites_most_common_color_per_make(conn):\n",
    "    res = conn.execute('''SELECT FinalTable.Make, FinalTable.Color    \n",
    "                            FROM    \n",
    "                             ((SELECT tickets.Make, tickets.Color, Count(tickets.Color) AS color_count\n",
    "                              FROM tickets\n",
    "                              GROUP BY tickets.Make, tickets.Color) As CountMakeColor\n",
    "                            JOIN\n",
    "                             (SELECT dT.Make, Max(dT.color_count) As max_color_count\n",
    "                              FROM\n",
    "                                   (SELECT tickets.Make, tickets.Color, Count(tickets.Color) AS color_count\n",
    "                                    FROM tickets\n",
    "                                    GROUP BY tickets.Make, tickets.Color) As dT\n",
    "                              GROUP BY dT.Make) As MaxColorCount\n",
    "                              \n",
    "                        ON CountMakeColor.Make = MaxColorCount.Make \n",
    "                        AND CountMakeColor.color_count = MaxColorCount.max_color_count) as FinalTable''')\n",
    "\n",
    "    res_dict = dict()\n",
    "    for i in res:\n",
    "        res_dict[i[0]] = i[1]\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def pandas_first_ticket_per_make(df):\n",
    "    df_sorted = df.sort_values(by = ['Issue Date', \"Issue time\"])\n",
    "    result_series = df_sorted.groupby('Make')['Ticket number'].agg(lambda x: x.tolist()[0])\n",
    "    return result_series.to_dict()\n",
    "\n",
    "\n",
    "def sqlite_first_ticket_per_make(conn):\n",
    "    #TODO: add time to comparison\n",
    "    res = conn.execute('''select Make, \"Ticket number\"\n",
    "                                from tickets JOIN \n",
    "                                (select Make as group_make, min(\"Issue Date\") as earliest_date \n",
    "                                from tickets \n",
    "                                group by group_make) \n",
    "                                on group_make = make and earliest_date = \"Issue Date\";''')\n",
    "\n",
    "    res_dict = dict()\n",
    "    for i in res:\n",
    "        res_dict[i[0]] = i[1]\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_timings(df, n):\n",
    "    if n:\n",
    "        df = df.sample(n=n)\n",
    "        \n",
    "    results = dict()\n",
    "    results['number_of_records'] = df.shape[0]\n",
    "    \n",
    "    \n",
    "    with sqlite3.connect(':memory:') as conn_mem, sqlite3.connect('tickets.db') as conn_disk:\n",
    "        df.to_sql('tickets', conn_mem, if_exists='replace')\n",
    "        df.to_sql('tickets', conn_disk, if_exists='replace')\n",
    "        \n",
    "        pandas_q1_start = time.time()\n",
    "        res_pd = pandas_most_common_makes(df)\n",
    "        pandas_q1_end = time.time()\n",
    "        \n",
    "        sql_q1_disk_start = time.time()\n",
    "        res_sql_disk = sqlite_most_common_names(conn_disk)\n",
    "        sql_q1_disk_end = time.time()\n",
    "        \n",
    "        sql_q1_mem_start = time.time()\n",
    "        res_sql_mem = sqlite_most_common_names(conn_mem)\n",
    "        sql_q1_mem_end = time.time()\n",
    "        \n",
    "        results['q1_pandas_time'] = pandas_q1_end - pandas_q1_start\n",
    "        results['q1_sql_disk_time'] = sql_q1_disk_end - sql_q1_disk_start\n",
    "        results['q1_sql_mem_time'] = sql_q1_mem_end - sql_q1_mem_start\n",
    "        print(results)\n",
    "        \n",
    "        try:\n",
    "            assert sorted(res_pd) == sorted(res_sql_disk)\n",
    "        except:\n",
    "            print(sorted(res_pd))\n",
    "            print(sorted(res_sql_mem))\n",
    "            print('difference between pandas and sql, could still be valid in cases of ties: {}'.format(set(res_pd) ^ set(res_sql_disk)))\n",
    "\n",
    "            \n",
    "        # q2\n",
    "        print()\n",
    "        print('q2')\n",
    "        pandas_q2_start = time.time()\n",
    "        res_pd = pandas_most_common_color_per_make(df)\n",
    "        pandas_q2_end = time.time()\n",
    "        print(pandas_q2_end - pandas_q2_start)\n",
    "\n",
    "        sql_q2_disk_start = time.time()\n",
    "        res_sql_disk = sqlites_most_common_color_per_make(conn_disk)\n",
    "        sql_q2_disk_end = time.time()\n",
    "        print(sql_q2_disk_end - sql_q2_disk_start)\n",
    "\n",
    "        sql_q2_mem_start = time.time()\n",
    "        res_sql_mem = sqlites_most_common_color_per_make(conn_mem)\n",
    "        sql_q2_mem_end = time.time()\n",
    "        print(sql_q2_mem_end - sql_q2_mem_start)\n",
    "        \n",
    "        results['q2_pandas_time'] = pandas_q2_end - pandas_q2_start\n",
    "        results['q2_sql_disk_time'] = sql_q2_disk_end - sql_q2_disk_start\n",
    "        results['q2_sql_mem_time'] = sql_q2_mem_end - sql_q2_mem_start\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            assert res_pd == res_sql_disk\n",
    "        except:\n",
    "            set1 = set(res_pd.items())\n",
    "            set2 = set(res_sql_disk.items())\n",
    "            print(set1 ^ set2)\n",
    "            print('difference between pandas and sql, could still be valid in cases of ties: {}'.format(set1 ^ set2))\n",
    "            \n",
    "\n",
    "        # q3\n",
    "        print()\n",
    "        print('q3')\n",
    "        pandas_q3_start = time.time()\n",
    "        res_pd = pandas_first_ticket_per_make(df)\n",
    "        pandas_q3_end = time.time()\n",
    "        print(pandas_q2_end - pandas_q2_start)\n",
    "\n",
    "        sql_q3_disk_start = time.time()\n",
    "        res_sql_disk = sqlite_first_ticket_per_make(conn_disk)\n",
    "        sql_q3_disk_end = time.time()\n",
    "        print(sql_q3_disk_end - sql_q3_disk_start)\n",
    "\n",
    "        sql_q3_mem_start = time.time()\n",
    "        res_sql_mem = sqlite_first_ticket_per_make(conn_mem)\n",
    "        sql_q3_mem_end = time.time()\n",
    "        print(sql_q3_mem_end - sql_q3_mem_start)\n",
    "        \n",
    "        results['q3_pandas_time'] = pandas_q3_end - pandas_q3_start\n",
    "        results['q3_sql_disk_time'] = sql_q3_disk_end - sql_q3_disk_start\n",
    "        results['q3_sql_mem_time'] = sql_q3_mem_end - sql_q3_mem_start\n",
    "\n",
    "        try:\n",
    "            assert sorted(res_pd) == sorted(res_sql_disk)\n",
    "            assert sorted(res_sql_disk) == sorted(res_sql_mem)\n",
    "        except:\n",
    "            print(res_pd)\n",
    "            print(res_sql_disk)\n",
    "            print(res_sql_mem)\n",
    "            raise AssertionError\n",
    "        \n",
    "        return [results]\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here ['TOYT', 'HOND', 'FORD', 'NISS', 'CHEV', 'BMW', 'MERZ', 'KIA', 'VOLK', 'HYUN', 'DODG', 'LEXS', 'JEEP', 'AUDI', 'MAZD', 'GMC', 'OTHR', 'ACUR', 'TOYO', 'CHRY', 'INFI', 'SUBA', 'LNDR', 'MITS', 'MNNI']\n",
      "here ['TOYT', 'HOND', 'FORD', 'NISS', 'CHEV', 'BMW', 'MERZ', 'KIA', 'VOLK', 'HYUN', 'DODG', 'LEXS', 'JEEP', 'AUDI', 'MAZD', 'GMC', 'OTHR', 'ACUR', 'TOYO', 'CHRY', 'INFI', 'SUBA', 'LNDR', 'MITS', 'MNNI']\n",
      "{'number_of_records': 1000, 'q1_pandas_time': 0.0011854171752929688, 'q1_sql_disk_time': 0.0004982948303222656, 'q1_sql_mem_time': 0.0006983280181884766}\n",
      "['ACUR', 'AUDI', 'BMW', 'CHEV', 'CHRY', 'DODG', 'FORD', 'GMC', 'HOND', 'HYUN', 'INFI', 'JEEP', 'KIA', 'LEXS', 'LNDR', 'MAZD', 'MERZ', 'MITS', 'NISS', 'OTHR', 'SUBA', 'TOYO', 'TOYT', 'VOLK', 'VOLV']\n",
      "['ACUR', 'AUDI', 'BMW', 'CHEV', 'CHRY', 'DODG', 'FORD', 'GMC', 'HOND', 'HYUN', 'INFI', 'JEEP', 'KIA', 'LEXS', 'LNDR', 'MAZD', 'MERZ', 'MITS', 'MNNI', 'NISS', 'OTHR', 'SUBA', 'TOYO', 'TOYT', 'VOLK']\n",
      "difference between pandas and sql, could still be valid in cases of ties: {'MNNI', 'VOLV'}\n",
      "\n",
      "q2\n",
      "0.03162336349487305\n",
      "0.0009250640869140625\n",
      "0.0009183883666992188\n",
      "{('PONT', 'SL'), ('PONT', 'TN'), ('TOYO', 'GY'), ('TOYO', 'GR'), ('HOND', 'BK'), ('BUIC', 'WT'), ('JEEP', 'BK'), ('HOND', 'GY'), ('JEEP', 'GY'), ('BUIC', 'BN'), ('INFI', 'BK'), ('INFI', 'GY')}\n",
      "difference between pandas and sql, could still be valid in cases of ties: {('PONT', 'SL'), ('PONT', 'TN'), ('TOYO', 'GY'), ('TOYO', 'GR'), ('HOND', 'BK'), ('BUIC', 'WT'), ('JEEP', 'BK'), ('HOND', 'GY'), ('JEEP', 'GY'), ('BUIC', 'BN'), ('INFI', 'BK'), ('INFI', 'GY')}\n",
      "\n",
      "q3\n",
      "0.03162336349487305\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "near \")\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-50f4b6142cc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_timings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_with_make\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mres_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-9186b7f69f74>\u001b[0m in \u001b[0;36mrun_timings\u001b[0;34m(df, n)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0msql_q3_disk_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mres_sql_disk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite_first_ticket_per_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_disk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0msql_q3_disk_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_q3_disk_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msql_q3_disk_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-006f59284cd6>\u001b[0m in \u001b[0;36msqlite_first_ticket_per_make\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m     56\u001b[0m                                 \u001b[0;32mfrom\u001b[0m \u001b[0mtickets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                 group by group_make) \n\u001b[0;32m---> 58\u001b[0;31m                                 on group_make = make and earliest_date = \"Issue Date\" || \"Issue time\");''')\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mres_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: near \")\": syntax error"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "df_with_make = df.dropna(subset= ['Make'])\n",
    "\n",
    "for i in [1000, 2000, 4000, 8000, 16000, 32000, 64000, 128000, 256000, None]:\n",
    "    results.extend(run_timings(df_with_make, i))\n",
    "    \n",
    "res_df = pd.DataFrame.from_dict(results)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['q1_sql_speed_difference'] = res_df['q1_sql_mem_time']/res_df['q1_pandas_time']\n",
    "res_df['q2_sql_speed_difference'] = res_df['q2_sql_mem_time']/res_df['q2_pandas_time']\n",
    "res_df['q3_sql_speed_difference'] = res_df['q3_sql_mem_time']/res_df['q3_pandas_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_records</th>\n",
       "      <th>q1_pandas_time</th>\n",
       "      <th>q1_sql_disk_time</th>\n",
       "      <th>q1_sql_mem_time</th>\n",
       "      <th>q2_pandas_time</th>\n",
       "      <th>q2_sql_disk_time</th>\n",
       "      <th>q2_sql_mem_time</th>\n",
       "      <th>q3_pandas_time</th>\n",
       "      <th>q3_sql_disk_time</th>\n",
       "      <th>q3_sql_mem_time</th>\n",
       "      <th>q1_sql_speed_difference</th>\n",
       "      <th>q2_sql_speed_difference</th>\n",
       "      <th>q3_sql_speed_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.032973</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.419819</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>0.126869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.031511</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.658897</td>\n",
       "      <td>0.054037</td>\n",
       "      <td>0.228488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.035756</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.987677</td>\n",
       "      <td>0.092443</td>\n",
       "      <td>0.318327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.059387</td>\n",
       "      <td>0.013836</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>1.234575</td>\n",
       "      <td>0.142299</td>\n",
       "      <td>1.032381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.060485</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.014569</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>2.720749</td>\n",
       "      <td>0.240862</td>\n",
       "      <td>0.502885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32000</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.008286</td>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.067023</td>\n",
       "      <td>0.028697</td>\n",
       "      <td>0.028175</td>\n",
       "      <td>0.020543</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>2.959317</td>\n",
       "      <td>0.420380</td>\n",
       "      <td>0.822522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64000</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.021107</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>0.099973</td>\n",
       "      <td>0.071681</td>\n",
       "      <td>0.073004</td>\n",
       "      <td>0.038789</td>\n",
       "      <td>0.044285</td>\n",
       "      <td>0.041662</td>\n",
       "      <td>4.489534</td>\n",
       "      <td>0.730242</td>\n",
       "      <td>1.074060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128000</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.039917</td>\n",
       "      <td>0.039057</td>\n",
       "      <td>0.131376</td>\n",
       "      <td>0.146188</td>\n",
       "      <td>0.134304</td>\n",
       "      <td>0.071325</td>\n",
       "      <td>0.091121</td>\n",
       "      <td>0.075312</td>\n",
       "      <td>4.978786</td>\n",
       "      <td>1.022287</td>\n",
       "      <td>1.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256000</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.079597</td>\n",
       "      <td>0.080120</td>\n",
       "      <td>0.178373</td>\n",
       "      <td>0.286304</td>\n",
       "      <td>0.284016</td>\n",
       "      <td>0.134186</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.155036</td>\n",
       "      <td>5.354424</td>\n",
       "      <td>1.592257</td>\n",
       "      <td>1.155381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4357544</td>\n",
       "      <td>0.197369</td>\n",
       "      <td>1.541899</td>\n",
       "      <td>1.499423</td>\n",
       "      <td>1.127066</td>\n",
       "      <td>6.160068</td>\n",
       "      <td>5.955270</td>\n",
       "      <td>1.578308</td>\n",
       "      <td>3.006889</td>\n",
       "      <td>3.095549</td>\n",
       "      <td>7.597057</td>\n",
       "      <td>5.283869</td>\n",
       "      <td>1.961309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_records  q1_pandas_time  q1_sql_disk_time  q1_sql_mem_time  \\\n",
       "0               1000        0.001292          0.000437         0.000542   \n",
       "1               2000        0.001033          0.000596         0.000681   \n",
       "2               4000        0.001161          0.001065         0.001147   \n",
       "3               8000        0.002164          0.004309         0.002671   \n",
       "4              16000        0.001744          0.004180         0.004746   \n",
       "5              32000        0.002737          0.008286         0.008099   \n",
       "6              64000        0.004294          0.021107         0.019279   \n",
       "7             128000        0.007845          0.039917         0.039057   \n",
       "8             256000        0.014963          0.079597         0.080120   \n",
       "9            4357544        0.197369          1.541899         1.499423   \n",
       "\n",
       "   q2_pandas_time  q2_sql_disk_time  q2_sql_mem_time  q3_pandas_time  \\\n",
       "0        0.032973          0.001357         0.001264        0.004226   \n",
       "1        0.031511          0.001774         0.001703        0.004261   \n",
       "2        0.035756          0.003420         0.003305        0.006408   \n",
       "3        0.059387          0.013836         0.008451        0.007716   \n",
       "4        0.060485          0.017065         0.014569        0.016195   \n",
       "5        0.067023          0.028697         0.028175        0.020543   \n",
       "6        0.099973          0.071681         0.073004        0.038789   \n",
       "7        0.131376          0.146188         0.134304        0.071325   \n",
       "8        0.178373          0.286304         0.284016        0.134186   \n",
       "9        1.127066          6.160068         5.955270        1.578308   \n",
       "\n",
       "   q3_sql_disk_time  q3_sql_mem_time  q1_sql_speed_difference  \\\n",
       "0          0.000614         0.000536                 0.419819   \n",
       "1          0.001010         0.000974                 0.658897   \n",
       "2          0.002155         0.002040                 0.987677   \n",
       "3          0.007383         0.007966                 1.234575   \n",
       "4          0.009354         0.008144                 2.720749   \n",
       "5          0.017242         0.016897                 2.959317   \n",
       "6          0.044285         0.041662                 4.489534   \n",
       "7          0.091121         0.075312                 4.978786   \n",
       "8          0.159091         0.155036                 5.354424   \n",
       "9          3.006889         3.095549                 7.597057   \n",
       "\n",
       "   q2_sql_speed_difference  q3_sql_speed_difference  \n",
       "0                 0.038323                 0.126869  \n",
       "1                 0.054037                 0.228488  \n",
       "2                 0.092443                 0.318327  \n",
       "3                 0.142299                 1.032381  \n",
       "4                 0.240862                 0.502885  \n",
       "5                 0.420380                 0.822522  \n",
       "6                 0.730242                 1.074060  \n",
       "7                 1.022287                 1.055900  \n",
       "8                 1.592257                 1.155381  \n",
       "9                 5.283869                 1.961309  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My metrics show that my pandas code is faster at large data sizes and scales better. I find the pandas much simpler to write and understand, it is objectively much shorter.\n",
    "\n",
    "I was surprized that sqlite was slower, it is possible that my sql code is not optimal but the benchmarks linked below show that pandas can outperform sqlite for joining and grouping operations. My code uses both.\n",
    "\n",
    "https://blog.thedataincubator.com/2018/05/sqlite-vs-pandas-performance-benchmarks/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket number</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>Issue time</th>\n",
       "      <th>Meter Id</th>\n",
       "      <th>Marked Time</th>\n",
       "      <th>RP State Plate</th>\n",
       "      <th>Plate Expiry Date</th>\n",
       "      <th>VIN</th>\n",
       "      <th>Make</th>\n",
       "      <th>Body Style</th>\n",
       "      <th>Color</th>\n",
       "      <th>Location</th>\n",
       "      <th>Route</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Violation code</th>\n",
       "      <th>Violation Description</th>\n",
       "      <th>Fine amount</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1103341116</td>\n",
       "      <td>2015-12-21T00:00:00</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>200304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PA</td>\n",
       "      <td>GY</td>\n",
       "      <td>13147 WELBY WAY</td>\n",
       "      <td>01521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4000A1</td>\n",
       "      <td>NO EVIDENCE OF REG</td>\n",
       "      <td>50.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1103700150</td>\n",
       "      <td>2015-12-21T00:00:00</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>201512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VN</td>\n",
       "      <td>WH</td>\n",
       "      <td>525 S MAIN ST</td>\n",
       "      <td>1C51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4000A1</td>\n",
       "      <td>NO EVIDENCE OF REG</td>\n",
       "      <td>50.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1104803000</td>\n",
       "      <td>2015-12-21T00:00:00</td>\n",
       "      <td>2055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>201503.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PA</td>\n",
       "      <td>BK</td>\n",
       "      <td>200 WORLD WAY</td>\n",
       "      <td>2R2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8939</td>\n",
       "      <td>WHITE CURB</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6439997.9</td>\n",
       "      <td>1802686.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104820732</td>\n",
       "      <td>2015-12-26T00:00:00</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PA</td>\n",
       "      <td>WH</td>\n",
       "      <td>100 WORLD WAY</td>\n",
       "      <td>2F11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>000</td>\n",
       "      <td>17104h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6440041.1</td>\n",
       "      <td>1802686.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105461453</td>\n",
       "      <td>2015-09-15T00:00:00</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>200316.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEV</td>\n",
       "      <td>PA</td>\n",
       "      <td>BK</td>\n",
       "      <td>GEORGIA ST/OLYMPIC</td>\n",
       "      <td>1FB70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8069A</td>\n",
       "      <td>NO STOPPING/STANDING</td>\n",
       "      <td>93.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticket number           Issue Date  Issue time Meter Id  Marked Time  \\\n",
       "0    1103341116  2015-12-21T00:00:00      1251.0      NaN          NaN   \n",
       "1    1103700150  2015-12-21T00:00:00      1435.0      NaN          NaN   \n",
       "2    1104803000  2015-12-21T00:00:00      2055.0      NaN          NaN   \n",
       "3    1104820732  2015-12-26T00:00:00      1515.0      NaN          NaN   \n",
       "4    1105461453  2015-09-15T00:00:00       115.0      NaN          NaN   \n",
       "\n",
       "  RP State Plate  Plate Expiry Date  VIN  Make Body Style Color  \\\n",
       "0             CA           200304.0  NaN   NaN         PA    GY   \n",
       "1             CA           201512.0  NaN   NaN         VN    WH   \n",
       "2             CA           201503.0  NaN   NaN         PA    BK   \n",
       "3             CA                NaN  NaN   NaN         PA    WH   \n",
       "4             CA           200316.0  NaN  CHEV         PA    BK   \n",
       "\n",
       "             Location  Route  Agency Violation code Violation Description  \\\n",
       "0     13147 WELBY WAY  01521     1.0         4000A1    NO EVIDENCE OF REG   \n",
       "1       525 S MAIN ST   1C51     1.0         4000A1    NO EVIDENCE OF REG   \n",
       "2       200 WORLD WAY    2R2     2.0           8939            WHITE CURB   \n",
       "3       100 WORLD WAY   2F11     2.0            000                17104h   \n",
       "4  GEORGIA ST/OLYMPIC  1FB70     1.0          8069A  NO STOPPING/STANDING   \n",
       "\n",
       "   Fine amount   Latitude  Longitude  \n",
       "0         50.0    99999.0    99999.0  \n",
       "1         50.0    99999.0    99999.0  \n",
       "2         58.0  6439997.9  1802686.4  \n",
       "3          NaN  6440041.1  1802686.2  \n",
       "4         93.0    99999.0    99999.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
